{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Daftar sparepart dan mapping ke indeks\n",
    "spareparts = ['spion', 'busi', 'lampu_depan', 'lampu_belakang', 'sein']\n",
    "sparepart_to_index = {sp: i for i, sp in enumerate(spareparts)}\n",
    "\n",
    "def derive_bbox(sparepart, width=150, height=150):\n",
    "    if sparepart == 'spion':\n",
    "        xmin = int(0.3*width)\n",
    "        ymin = int(0.4*height)\n",
    "        xmax = int(0.7*width)\n",
    "        ymax = int(0.9*height)\n",
    "    elif sparepart == 'busi':\n",
    "        xmin = int(0.4*width)\n",
    "        ymin = int(0.1*height)\n",
    "        xmax = int(0.6*width)\n",
    "        ymax = int(0.8*height)\n",
    "    elif sparepart == 'lampu_depan':\n",
    "        xmin = int(0.3*width)\n",
    "        ymin = int(0.3*height)\n",
    "        xmax = int(0.7*width)\n",
    "        ymax = int(0.7*height)\n",
    "    elif sparepart == 'lampu_belakang':\n",
    "        xmin = int(0.35*width)\n",
    "        ymin = int(0.4*height)\n",
    "        xmax = int(0.65*width)\n",
    "        ymax = int(0.7*height)\n",
    "    elif sparepart == 'sein':\n",
    "        xmin = int(0.3*width)\n",
    "        ymin = int(0.2*height)\n",
    "        xmax = int(0.7*width)\n",
    "        ymax = int(0.8*height)\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "class SparepartDataset(Dataset):\n",
    "    def __init__(self, root_dir='data/train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # Load all images\n",
    "        for sp in spareparts:\n",
    "            for q in ['baik','sedang','buruk']:\n",
    "                d = os.path.join(root_dir, sp, q)\n",
    "                files = os.listdir(d)\n",
    "                for f in files:\n",
    "                    if f.endswith('.png'):\n",
    "                        img_path = os.path.join(d, f)\n",
    "                        self.samples.append((img_path, sp))\n",
    "                        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, sp = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = sparepart_to_index[sp]\n",
    "        bbox = derive_bbox(sp)\n",
    "        w, h = img.size\n",
    "        bbox_norm = [bbox[0]/w, bbox[1]/h, bbox[2]/w, bbox[3]/h]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label, torch.tensor(bbox_norm, dtype=torch.float32)\n",
    "\n",
    "# Simple CNN Model with two heads: classification & bbox regression\n",
    "class SparepartModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SparepartModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*(224//8)*(224//8),256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "        self.bbox_regressor = nn.Linear(256,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        class_logits = self.classifier(x)\n",
    "        bbox = self.bbox_regressor(x)\n",
    "        return class_logits, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cpu\n",
      "INFO: Loaded 212 samples dari data/train\n",
      "ERROR: Gambar tidak valid data/train/spion/spion_57.png: cannot identify image file '/Users/Adam/Desktop/bangkit/percobaan capstone/data/train/spion/spion_57.png'\n",
      "WARNING: Total gambar tidak valid yang ditemukan: 1\n",
      "INFO: Menghapus 1 gambar tidak valid.\n",
      "INFO: Loaded 54 samples dari data/validation\n",
      "INFO: Semua gambar valid.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "INFO: Model initialized and moved to device.\n",
      "INFO: Loss functions, optimizer, and scheduler are set up.\n",
      "INFO: Epoch 1/20, Loss: 1.9766\n",
      "INFO: Validation Loss: 1.2004, Accuracy: 94.44%\n",
      "INFO: Model saved to best_model_sparepart.h5 in .h5 format.\n",
      "INFO: Model terbaik disimpan dengan akurasi 94.44% dalam format .h5\n",
      "INFO: Epoch 2/20, Loss: 0.3465\n",
      "INFO: Validation Loss: 0.0271, Accuracy: 100.00%\n",
      "INFO: Model saved to best_model_sparepart.h5 in .h5 format.\n",
      "INFO: Model terbaik disimpan dengan akurasi 100.00% dalam format .h5\n",
      "INFO: Epoch 3/20, Loss: 0.0417\n",
      "INFO: Validation Loss: 0.0048, Accuracy: 100.00%\n",
      "INFO: Epoch 4/20, Loss: 0.0137\n",
      "INFO: Validation Loss: 0.0047, Accuracy: 100.00%\n",
      "INFO: Epoch 5/20, Loss: 0.0079\n",
      "INFO: Validation Loss: 0.0030, Accuracy: 100.00%\n",
      "INFO: Epoch 6/20, Loss: 0.0069\n",
      "INFO: Validation Loss: 0.0022, Accuracy: 100.00%\n",
      "INFO: Epoch 7/20, Loss: 0.0102\n",
      "INFO: Validation Loss: 0.0017, Accuracy: 100.00%\n",
      "INFO: Epoch 8/20, Loss: 0.0052\n",
      "INFO: Validation Loss: 0.0014, Accuracy: 100.00%\n",
      "INFO: Epoch 9/20, Loss: 0.0110\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 10/20, Loss: 0.0065\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 11/20, Loss: 0.0057\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 12/20, Loss: 0.0050\n",
      "INFO: Validation Loss: 0.0014, Accuracy: 100.00%\n",
      "INFO: Epoch 13/20, Loss: 0.0053\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 14/20, Loss: 0.0079\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 15/20, Loss: 0.0064\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 16/20, Loss: 0.0039\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 17/20, Loss: 0.0056\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 18/20, Loss: 0.0057\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 19/20, Loss: 0.0050\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Epoch 20/20, Loss: 0.0042\n",
      "INFO: Validation Loss: 0.0013, Accuracy: 100.00%\n",
      "INFO: Training selesai.\n",
      "INFO: Model saved to model_sparepart_final.h5 in .h5 format.\n",
      "INFO: Model disimpan sebagai 'model_sparepart_final.h5'\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "INFO: Model loaded from best_model_sparepart.h5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparepartModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=17, bias=True)\n",
       "  )\n",
       "  (bbox_regressor): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import logging\n",
    "from torchvision import models\n",
    "import h5py  # Import h5py for HDF5 support\n",
    "\n",
    "# ============================\n",
    "# 1. Setup and Configuration\n",
    "# ============================\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device: {device}')\n",
    "\n",
    "# ============================\n",
    "# 2. Data Preparation\n",
    "# ============================\n",
    "\n",
    "# Daftar sparepart dan mapping ke indeks\n",
    "spareparts = [\n",
    "    'spion', 'knalpot', 'spion_rusak', 'motor_lecet',\n",
    "    'honda_beat_biru_putih', 'honda_beat_hijau', 'honda_beat_hitam', 'honda_beat_silver',\n",
    "    'honda_vario_hitam', 'honda_vario_putih',\n",
    "    'yamaha_aerox_hitam', 'yamaha_aerox_kuning', 'yamaha_aerox_putih',\n",
    "    'yamaha_nmax_hitam', 'yamaha_nmax_merah', 'yamaha_nmax_putih',\n",
    "    'plat_nomor'\n",
    "]\n",
    "sparepart_to_index = {sp: i for i, sp in enumerate(spareparts)}\n",
    "num_classes = len(spareparts)\n",
    "\n",
    "def derive_bbox(sparepart, width=224, height=224):\n",
    "    \"\"\"\n",
    "    Menghasilkan bounding box yang dinormalisasi berdasarkan nama sparepart.\n",
    "    Menyesuaikan dengan fungsi generate_dummy_image.\n",
    "    \"\"\"\n",
    "    if sparepart in ['spion', 'spion_rusak']:\n",
    "        xmin = int(0.3 * width)\n",
    "        ymin = int(0.4 * height)\n",
    "        xmax = int(0.7 * width)\n",
    "        ymax = int(0.9 * height)\n",
    "    elif sparepart == 'knalpot':\n",
    "        xmin = int(0.3 * width)\n",
    "        ymin = int(0.3 * height)\n",
    "        xmax = int(0.7 * width)\n",
    "        ymax = int(0.7 * height)\n",
    "    elif sparepart == 'motor_lecet':\n",
    "        xmin = int(0.2 * width)\n",
    "        ymin = int(0.2 * height)\n",
    "        xmax = int(0.8 * width)\n",
    "        ymax = int(0.8 * height)\n",
    "    elif sparepart.startswith('honda') or sparepart.startswith('yamaha'):\n",
    "        xmin = int(0.2 * width)\n",
    "        ymin = int(0.3 * height)\n",
    "        xmax = int(0.8 * width)\n",
    "        ymax = int(0.6 * height)\n",
    "    elif sparepart == 'plat_nomor':\n",
    "        xmin = int(0.1 * width)\n",
    "        ymin = int(0.4 * height)\n",
    "        xmax = int(0.9 * width)\n",
    "        ymax = int(0.6 * height)\n",
    "    else:\n",
    "        # Default bounding box jika sparepart tidak dikenali\n",
    "        xmin = int(0.3 * width)\n",
    "        ymin = int(0.3 * height)\n",
    "        xmax = int(0.7 * width)\n",
    "        ymax = int(0.7 * height)\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "class SparepartDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, sp = self.samples[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except (UnidentifiedImageError, IOError) as e:\n",
    "            logging.error(f\"Error loading image {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        label = sparepart_to_index.get(sp)\n",
    "        if label is None:\n",
    "            logging.error(f\"Label untuk sparepart '{sp}' tidak ditemukan di {img_path}.\")\n",
    "            raise ValueError(f\"Label tidak valid untuk gambar {img_path}\")\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        bbox = derive_bbox(sp, width=224, height=224)\n",
    "        bbox_norm = [bbox[0]/224, bbox[1]/224, bbox[2]/224, bbox[3]/224]\n",
    "        \n",
    "        return img, label, torch.tensor(bbox_norm, dtype=torch.float32)\n",
    "\n",
    "def load_dataset(root_dir):\n",
    "    samples = []\n",
    "    for sp in spareparts:\n",
    "        d = os.path.join(root_dir, sp)\n",
    "        if not os.path.isdir(d):\n",
    "            logging.warning(f\"Directory {d} tidak ada. Melewati.\")\n",
    "            continue\n",
    "        files = os.listdir(d)\n",
    "        for f in files:\n",
    "            if f.endswith('.png'):\n",
    "                img_path = os.path.join(d, f)\n",
    "                samples.append((img_path, sp))\n",
    "    logging.info(f\"Loaded {len(samples)} samples dari {root_dir}\")\n",
    "    return samples\n",
    "\n",
    "def validate_dataset(samples):\n",
    "    valid_samples = []\n",
    "    invalid_files = []\n",
    "    for img_path, sp in samples:\n",
    "        if sp not in sparepart_to_index:\n",
    "            logging.error(f\"Sparepart '{sp}' tidak dikenali. Melewati {img_path}.\")\n",
    "            continue\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img.close()\n",
    "            valid_samples.append((img_path, sp))\n",
    "        except (UnidentifiedImageError, IOError) as e:\n",
    "            invalid_files.append(img_path)\n",
    "            logging.error(f\"Gambar tidak valid {img_path}: {e}\")\n",
    "    \n",
    "    if invalid_files:\n",
    "        logging.warning(f\"Total gambar tidak valid yang ditemukan: {len(invalid_files)}\")\n",
    "        logging.info(f\"Menghapus {len(invalid_files)} gambar tidak valid.\")\n",
    "    else:\n",
    "        logging.info(\"Semua gambar valid.\")\n",
    "    \n",
    "    return valid_samples\n",
    "\n",
    "# Transformasi untuk data dengan augmentasi\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 3. Model Definition\n",
    "# ============================\n",
    "\n",
    "# Menggunakan pre-trained ResNet50 dengan modifikasi untuk multi-task learning\n",
    "class SparepartModel(nn.Module):\n",
    "    def __init__(self, num_classes=17, pretrained=True):\n",
    "        super(SparepartModel, self).__init__()\n",
    "        self.backbone = models.resnet50(pretrained=pretrained)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Head untuk klasifikasi\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Head untuk bounding box regression\n",
    "        self.bbox_regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        class_logits = self.classifier(features)\n",
    "        bbox = self.bbox_regressor(features)\n",
    "        return class_logits, bbox\n",
    "\n",
    "# ============================\n",
    "# 4. Helper Functions for .h5\n",
    "# ============================\n",
    "\n",
    "def save_model_h5(model, filepath):\n",
    "    \"\"\"\n",
    "    Saves the model's state_dict to an HDF5 (.h5) file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to save.\n",
    "        filepath (str): The path where the .h5 file will be saved.\n",
    "    \"\"\"\n",
    "    state_dict = model.state_dict()\n",
    "    with h5py.File(filepath, 'w') as f:\n",
    "        for key, value in state_dict.items():\n",
    "            f.create_dataset(key, data=value.cpu().numpy())\n",
    "    logging.info(f\"Model saved to {filepath} in .h5 format.\")\n",
    "\n",
    "def load_model_h5(model, filepath):\n",
    "    \"\"\"\n",
    "    Loads the model's state_dict from an HDF5 (.h5) file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to load the state_dict into.\n",
    "        filepath (str): The path to the .h5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        state_dict = {}\n",
    "        for key in f.keys():\n",
    "            state_dict[key] = torch.tensor(f[key][...])\n",
    "    model.load_state_dict(state_dict)\n",
    "    logging.info(f\"Model loaded from {filepath}.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Data Loading\n",
    "# ============================\n",
    "\n",
    "# Load dan validasi data training\n",
    "train_samples = load_dataset('data/train')\n",
    "train_samples = validate_dataset(train_samples)\n",
    "\n",
    "# Pastikan tidak ada sampel dengan label tidak valid\n",
    "train_samples = [s for s in train_samples if s[1] in sparepart_to_index]\n",
    "\n",
    "train_dataset = SparepartDataset(train_samples, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Load dan validasi data validasi\n",
    "validation_samples = load_dataset('data/validation')\n",
    "validation_samples = validate_dataset(validation_samples)\n",
    "validation_samples = [s for s in validation_samples if s[1] in sparepart_to_index]\n",
    "validation_dataset = SparepartDataset(validation_samples, transform=val_transform)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ============================\n",
    "# 6. Model Initialization\n",
    "# ============================\n",
    "\n",
    "# Inisialisasi model\n",
    "model = SparepartModel(num_classes=num_classes, pretrained=True)\n",
    "model.to(device)\n",
    "logging.info(\"Model initialized and moved to device.\")\n",
    "\n",
    "# ============================\n",
    "# 7. Loss Function and Optimizer\n",
    "# ============================\n",
    "\n",
    "# Menghitung class weights\n",
    "class_counts = {}\n",
    "for _, sp in train_samples:\n",
    "    class_counts[sp] = class_counts.get(sp, 0) + 1\n",
    "epsilon = 1e-6\n",
    "class_weights = []\n",
    "for sp in spareparts:\n",
    "    count = class_counts.get(sp, 0)\n",
    "    if count > 0:\n",
    "        class_weights.append(1.0 / (count + epsilon))\n",
    "    else:\n",
    "        class_weights.append(1.0)  # Atur bobot default untuk kelas tanpa sampel\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion_class = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion_bbox = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "logging.info(\"Loss functions, optimizer, and scheduler are set up.\")\n",
    "\n",
    "# ============================\n",
    "# 8. Training Loop\n",
    "# ============================\n",
    "\n",
    "# Training loop dengan perbaikan\n",
    "num_epochs = 20\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, bboxes in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_class, outputs_bbox = model(images)\n",
    "        loss_class = criterion_class(outputs_class, labels)\n",
    "        loss_bbox = criterion_bbox(outputs_bbox, bboxes)\n",
    "        loss = loss_class + loss_bbox\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    logging.info(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            bboxes = bboxes.to(device)\n",
    "            \n",
    "            outputs_class, outputs_bbox = model(images)\n",
    "            loss_class = criterion_class(outputs_class, labels)\n",
    "            loss_bbox = criterion_bbox(outputs_bbox, bboxes)\n",
    "            loss = loss_class + loss_bbox\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs_class, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(validation_dataset)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    logging.info(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Menyimpan model terbaik dalam format .h5\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        save_model_h5(model, 'best_model_sparepart.h5')\n",
    "        logging.info(f\"Model terbaik disimpan dengan akurasi {best_val_accuracy:.2f}% dalam format .h5\")\n",
    "\n",
    "logging.info(\"Training selesai.\")\n",
    "\n",
    "# Menyimpan model akhir dalam format .h5\n",
    "save_model_h5(model, 'model_sparepart_final.h5')\n",
    "logging.info(\"Model disimpan sebagai 'model_sparepart_final.h5'\")\n",
    "\n",
    "# ============================\n",
    "# 9. Optional: Loading the Model\n",
    "# ============================\n",
    "\n",
    "# Jika Anda ingin memuat model dari file .h5, gunakan kode berikut:\n",
    "model = SparepartModel(num_classes=num_classes, pretrained=False)  # Set pretrained=False if loading state_dict\n",
    "load_model_h5(model, 'best_model_sparepart.h5')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from h5py) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device: cpu\n",
      "/var/folders/z6/9n120bs12z1_j_qxhrdxr2300000gp/T/ipykernel_7767/90200859.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "INFO: Model loaded successfully from 'model_sparepart.pth'.\n",
      "INFO: Arahkan kamera ke objek (sparepart).\n",
      "INFO: Tekan 'Space' untuk mengambil gambar, 'q' untuk keluar tanpa mengambil gambar.\n",
      "2024-12-11 20:52:30.541 python[7767:206506] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-11 20:52:30.541 python[7767:206506] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "INFO: Gambar diambil untuk prediksi.\n",
      "INFO: Predicted Class: spion_rusak\n",
      "INFO: Predicted Bounding Box: (83, 61), (216, 252)\n",
      "INFO: Tekan sembarang tombol pada jendela gambar untuk menutup.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# ------------------------- Setup Logging -------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------- Define Spareparts List -------------------------\n",
    "spareparts = [\n",
    "    'spion', 'knalpot', 'spion_rusak', 'motor_lecet',\n",
    "    'honda_beat_biru_putih', 'honda_beat_hijau', 'honda_beat_hitam', 'honda_beat_silver',\n",
    "    'honda_vario_hitam', 'honda_vario_putih',\n",
    "    'yamaha_aerox_hitam', 'yamaha_aerox_kuning', 'yamaha_aerox_putih',\n",
    "    'yamaha_nmax_hitam', 'yamaha_nmax_merah', 'yamaha_nmax_putih',\n",
    "    'plat_nomor'\n",
    "]\n",
    "\n",
    "# ------------------------- Define the Model Class -------------------------\n",
    "class SparepartModel(nn.Module):\n",
    "    def __init__(self, num_classes=17):\n",
    "        super(SparepartModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 112x112\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 56x56\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)   # 28x28\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "        self.bbox_regressor = nn.Linear(256, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        class_logits = self.classifier(x)\n",
    "        bbox = self.bbox_regressor(x)\n",
    "        return class_logits, bbox\n",
    "\n",
    "# ------------------------- Device Configuration -------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------- Initialize and Load the Model -------------------------\n",
    "model = SparepartModel(num_classes=len(spareparts))\n",
    "model_path = 'model_sparepart.pth'  # Update the path if necessary\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    logging.info(f\"Model loaded successfully from '{model_path}'.\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Model file '{model_path}' not found. Please ensure the file exists.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading the model: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ------------------------- Define Image Transform -------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ------------------------- Open the Camera -------------------------\n",
    "cap = cv2.VideoCapture(0)  # 0 is the default camera\n",
    "\n",
    "if not cap.isOpened():\n",
    "    logging.error(\"Tidak dapat membuka kamera. Pastikan kamera tersedia.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "logging.info(\"Arahkan kamera ke objek (sparepart).\")\n",
    "logging.info(\"Tekan 'Space' untuk mengambil gambar, 'q' untuk keluar tanpa mengambil gambar.\")\n",
    "\n",
    "captured = False\n",
    "frame = None  # Initialize frame variable\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        logging.error(\"Gagal menangkap frame dari kamera.\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Camera (Tekan 'Space' untuk memfoto)\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # Uncomment the line below for debugging key presses\n",
    "    # logging.debug(f\"Key pressed: {key}\")\n",
    "\n",
    "    if key == ord('q'):\n",
    "        # Keluar tanpa mengambil gambar\n",
    "        logging.info(\"Keluar tanpa mengambil gambar.\")\n",
    "        break\n",
    "    elif key == ord(' '):  # Space key\n",
    "        # User menekan space, ambil foto ini untuk prediksi\n",
    "        captured = True\n",
    "        logging.info(\"Gambar diambil untuk prediksi.\")\n",
    "        break\n",
    "\n",
    "# ------------------------- If Image Captured, Perform Prediction -------------------------\n",
    "if captured and frame is not None:\n",
    "    try:\n",
    "        # Preprocess the captured frame\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "\n",
    "        input_tensor = transform(pil_img).unsqueeze(0).to(device)  # (1,3,224,224)\n",
    "        with torch.no_grad():\n",
    "            class_logits, pred_bbox = model(input_tensor)\n",
    "            _, preds = torch.max(class_logits, 1)\n",
    "\n",
    "        # Denormalisasi bounding box\n",
    "        pred_box = pred_bbox[0].cpu().numpy()\n",
    "        h, w = 224, 224  # Since we resized the image to 224x224\n",
    "        xmin = int(pred_box[0] * w)\n",
    "        ymin = int(pred_box[1] * h)\n",
    "        xmax = int(pred_box[2] * w)\n",
    "        ymax = int(pred_box[3] * h)\n",
    "\n",
    "        # Validasi prediksi kelas\n",
    "        try:\n",
    "            pred_class = spareparts[preds[0].item()]\n",
    "        except IndexError:\n",
    "            logging.error(f\"Predicted class index {preds[0].item()} out of range.\")\n",
    "            pred_class = \"Unknown\"\n",
    "\n",
    "        logging.info(f\"Predicted Class: {pred_class}\")\n",
    "        logging.info(f\"Predicted Bounding Box: ({xmin}, {ymin}), ({xmax}, {ymax})\")\n",
    "\n",
    "        # Menampilkan prediksi pada gambar hasil foto\n",
    "        # Resize frame ke (224,224) agar sesuai dengan bbox yang diprediksi\n",
    "        resized_frame = cv2.resize(frame, (224, 224))\n",
    "        resized_frame = np.ascontiguousarray(resized_frame)\n",
    "\n",
    "        # Gambar bounding box\n",
    "        cv2.rectangle(resized_frame, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
    "        # Tulis nama kelas\n",
    "        cv2.putText(resized_frame, pred_class, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 0, 0), 1)\n",
    "\n",
    "        # Tampilkan hasil prediksi\n",
    "        cv2.imshow(\"Hasil Prediksi\", resized_frame)\n",
    "        logging.info(\"Tekan sembarang tombol pada jendela gambar untuk menutup.\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Hasil Prediksi\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Terjadi kesalahan saat memproses gambar: {e}\")\n",
    "\n",
    "# ------------------------- Release Resources -------------------------\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "logging.info(\"Selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
